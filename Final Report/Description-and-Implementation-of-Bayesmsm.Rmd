---
title: "Bayesmsm: An R package for longitunal causal analysis using Bayesian Marginal Structural Models"
date: "2024-07-02"
abstract: >
  Observational studies offer a viable, efficient, and low-cost design to readily gather evidence on exposure effects. Although more practical, exposure mechanism is nonrandomized and causal inference methods are required to draw causal conclusions. Popular approaches used in health research are predominantly frequentist methods. Bayesian approaches have unique estimation features that are useful in many settings, however, there is a general lack of open-access software packages to carry out these analyses. Our project seeks to address this gap by developing a user-friendly R package named “bayesmsm” for the implementation of the Bayesian Marginal Structural Models for longitudinal data with continuous or binary outcome.
draft: true
author:  
  - name: Xiao Yan
    affiliation: Dalla Lana School of Public Health, University of Toronto
    address:
    - Department of Biostatistics
    - Toronto, Canada
    url: https://github.com/XiaoYan-Clarence
    orcid: 0000-1721-1511-1101 (?)
    email:  Clarence.YXA@gmail.com
  - name: Kuan Liu
    affiliation:
    - Dalla Lana School of Public Health, University of Toronto
    address:
    - Department of Biostatistics, Toronto, Canada
    - Institute of Health Policy, Management and Evaluation, Toronto, Canada
    url: https://www.kuan-liu.com/
    email: kuan.liu@utoronto.ca
    orcid: 0000-0002-0912-0225 (?)
type: package
output: 
  rjtools::rjournal_article:
    self_contained: yes
    toc: no
bibliography: RJreferences.bib
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

devtools::install_github("Kuan-Liu-Lab/bayesmsm")
library(bayesmsm)

if (!require(tidyverse)){
  install.packages("tidyverse",repos="http://cran.r-project.org")
  library(tidyverse)
}
```

# Introduction

Interactive data graphics provides plots that allow users to interact
them. One of the most basic types of interaction is through tooltips,
where users are provided additional information about elements in the
plot by moving the cursor over the plot.

This paper will first review some R packages on interactive graphics and
their tooltip implementations. A new package \CRANpkg{ToOoOlTiPs} that
provides customized tooltips for plot, is introduced. Some example plots
will then be given to showcase how these tooltips help users to better
read the graphics.

# Longitudinal causal framework and Bayesian Marginal Structural Models (BMSMs)

## Notation

In our analytical framework, let $n$ be the total number of study
subjects enrolled indexed by $i, i = 1, \ldots, n$ and $J$ the number of
visits indexed by $j, j = 1, \ldots, J$ [@liuBayesianCausal]. $Y_i$,
$X_{ij}$, and $Z_{ij}$ are the random variables representing an
end-of-study response, covariates, and the treatment for individual $i$
at visit $j$. We also define the treatment history up to visit $j$ as
$\bar{Z}_{ij} = \{ Z_{i1}, \ldots, Z_{ij} \}$ with covariates
$\bar{X}_{ij} = \{ X_{i1}, \ldots, X_{ij} \}$. Further, we assume at
each visit $j$, $X_{ij}$ is measured first and treatment assignment
$Z_{ij}$ is decided after [@liuBayesianCausal].

## Causal structure

In the observational context of our study, we introduce a causal
structure that predicates the non-repeatedly measured outcome $Y$ on
time-varying treatments $Z$ and time-varying covariates $X$. Unlike
models with time-dependent outcomes, our focus is on the final outcome
which is influenced by the entire treatment history and past covariates.
\cite{liuRepeatedlyMeasured}

Figure 1 shows the causal structure for two consecutive visits, which is
the Directed Acyclic Graph (DAG) between treatment assignment,
covariates and the final outcome. A causal graph is a directed acyclic
graph in which the vertices (nodes) of the graph represent variables and
the directed edges (arrows) represent direct causal effects
\cite{robinsMarginalStructural}. Here, $w_1$ and $w_2$ are two baseline
covariates. The baseline covariates $W$ and time-varying covariates
$L_1, L_2$ potentially influence treatment assignments $Z_1, Z_2$, and
ultimately, the outcome $Y$. Each treatment decision $Z_j$ at visit $j$
is determined at the end of that visit, based on all previous
information. This DAG also assumes that there is no unmeasured
confounding, allowing us to better interpret the causal effect of
treatment on the outcome. \cite{liu2023section3}

Further, we assume that the treatment decisions are made independently
for each subject at each visit, i.e. there is no competition for
treatment resources between subjects at each visit
\cite{liuRepeatedlyMeasured}.

## Directed Acyclic Graph (DAG)

```{r}
library(DiagrammeR)
grViz("
    digraph causal {
    # Nodes
    node [shape=ellipse, style=filled, color=lightgray]
    Xij_minus1 [label = 'X_{ij-1}']
    Zij_minus1 [label = 'Z_{ij-1}']
    Xij [label = 'X_{ij}']
    Zij [label = 'Z_{ij}']
    Yi [label = 'Y_{i}']

    # Edges
    edge [color=black, arrowhead=vee]
    rankdir = LR
    Xij_minus1 -> {Zij_minus1 Xij Zij Yi}
    Zij_minus1 -> {Zij Xij Yi}
    Xij -> {Zij Yi}
    Zij -> Yi

    # Graph
    graph [overlap=false, fontsize=14, rankdir=LR]
    }")

```

## Data-generating mechanism causal framework

In our investigation, we construct a data-generating mechanism for a
non-repeatedly measured outcome $Y$. Under the data-generating
mechanism, causal inference with observational data can simply be viewed
as a prediction problem. \cite{liuRepeatedlyMeasured} The
data-generating mechanism focuses on expressing experimental and
observational relationships between treatment and outcome, and is
formulated to address causal problem using probability distributions.
The prediction problem can thus be framed as drawing inference from an
ideal population in which treatment is unconfounded, but the observed
data is confounded. The experimental data generating mechanism is
indexed by $\mathcal{E}$, which generates samples from the ideal
population where treatment assignment at each visit is independent of
the covariates given past treatment assignments, i.e.,
$Z_{ij} \perp X_{ij} | Z_{ij-1}$; the observational data generating
mechanism is indexed by $\mathcal{O}$, which generates samples from the
observed population where independence does not hold and treatment
assignment $Z_{ij}$ at visit $j$ depends on $\{X_{ij}, Z_{ij-1}\}$.
\cite{liuRepeatedlyMeasured}

Under such data-generating mechanism, we have two important assumptions.
The first assumption has already been stated above, which is
$Z_{ij} \perp X_{ij} | Z_{ij-1}$. The second positivity assumption
states that at each visit, any treatment sequence that is compatible
with the complete treatment history has a non-zero probability of
occuring, i.e. $0 < P(Z_{ij} | X_{ij}, Z_{ij-1}) < 1$ for
$j = 1, \ldots, J$. \cite{liu2023slides}

Under $\mathcal{E}$, we can specify the marginal outcome model as
\cite{liu2023slides}:

$$
   g_y( E_{\mathcal{E}}[{y}_{i} \mid \bar{z}_{iJ}]) = {\Theta} \
   \sum_{j=1}^J z_{ij}, \quad j=1,\ldots,J.
$$

We draw inference from an ideal population ($\mathcal{E}$) but with
observed data subject to confounding ($\mathcal{O}$). Here, ${\Theta}$
is known as the marginal treatment effect. For example, if we have a
binary time-varying treatment, ${\Theta}$ is interpreted as, for 1 unit
increase in the cumulative treatment, the expected value of $y_i$
increases by ${\Theta}$.

## Bayesian Framework

Let $Y$ represent the outcome variable, $A$ the matrix of treatment
variables, and $W$ the vector of patient weights. The number of
observations is $n$, and $\theta$ is the vector of causal parameters on
the mean, with $\sigma$ representing the standard deviation. The
weighted log-likelihood of the normal distribution is given by
\cite{shaliziLecture}:

$$
\text{weighted log}\mathcal{L}_{\text{normal}}(\theta, \sigma^2) = -\frac{n}{2} \log(\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{n} W_i (Y_i - A_i \theta)^2
$$

where $A_i$ is the $i$-th row of matrix $A$ and $W_i$ denotes the
treatment weight for the $i$-th patient.

Using Bayesian decision theory and importance sampling technique, we
maximize an expected utility function (a function involving only
$\theta$), $\textbf{u}_{\mathcal{E}}(\Theta, \bar{v}_{i}^*)$, via
posterior predictive inference \cite{liuBayesianCausal},

$$
\hat{\Theta} 
 = \text{argmax}_{\theta} \int_{\bar{v}_{i}^*}  u_{\mathcal{E}}(\Theta, \bar{v}_{i}^*)P_{\mathcal{E}}(\bar{v}_{i}^* \mid \textbf{V}_n) \ d\bar{v}_{i}^* 
= \text{argmax}_{\theta}\int_{\bar{v}_{i}^*}  u_{\mathcal{E}}(\Theta, \bar{v}_{i}^*) \frac{P_{\mathcal{E}}(\bar{v}_{i}^* \mid \textbf{V}_n) }{P_{\mathcal{O}}(\bar{v}_{i}^* \mid \textbf{V}_n)}P_{\mathcal{O}}(\bar{v}_{i}^* \mid \textbf{V}_n) \ d\bar{v}_{i}^* 
$$

where
$u(\Theta, \bar{v}_{i}^*)= \log P_{\mathcal{E}}( Y_{i}^* \mid \bar{z}_{iJ}^*; \Theta)$
is the utility function; and
$w_{i}^* = \frac{P_{\mathcal{E}}(\bar{v}_{i}^* \mid \textbf{v}_n)}{P_{\mathcal{O}}(\bar{v}_{i}^* \mid \textbf{v}_n)}$
can be expanded to treatment assignment weight \cite{liuBayesianCausal}:

$$
w_{i j}^{*}=\frac{E_{\alpha}\left[\prod_{l=1}^{j} P_{\mathcal{E}}\left(Z_{i l-1}^{*} \mid \bar{Z}_{i l-2}^{*}, \alpha_{l-1}\right) \mid \bar{z}_{1}, \ldots, \bar{z}_{n}\right]}{E_{\beta}\left[\prod_{l=1}^{j} P_{\mathcal{O}}\left(Z_{i l-1}^{*} \mid \bar{Z}_{i l-2}^{*}, \bar{X}_{i l-1}^{*}, \beta_{l-1}\right) \mid \mathbf{v}_{n}\right]}, \text { for } j=1, \ldots, k \text {. }
$$

Since the Bayesian decision argument offers a point estimate for the
marginal treatment effect where the uncertainty is not yet addressed, we
need to use the weighted likelihood bootstrap (WLB) method
\cite{liuBayesianCausal}. This WLB method allows us to obtain a
distribution of $\Theta$ by drawing $\pi$ from a uniform Dirichlet
distribution of and maximizing the $\pi$ weighted expected utility sum
$\sum_{i=1}^{n} \sum_{j=1}^{k+1} \pi_{i}^{(b)} w_{i j} \log P_{\mathcal{E}}\left(y_{i j} \mid \bar{z}_{i j-1} ; \Theta\right)$
with respect to $\Theta$ \cite{liuBayesianCausal}.

In applying the above methods to actual coding, we first code the
weighted log likelihood of normal distribution in R. In order for the
automation of sampling from the uniform Dirichlet distribution and then
maximizing the likelihood, we initialize three mean parameters to 0.1
and the variance parameter to 4. Then, in each bootstrap, we draw 1,000
samples of alpha, the size of the dataset, from Dirichlet distribution
with parameter alpha equal to 1. The weighted mean is set to 1 for each
observation. Finally, we maximize the weighted log likelihood function.

The Average Causal Effect (ACE), or the Average Treatment Effect (ATE),
is defined as \cite{dingFirstCourse}:

$$
  \tau = n^{-1} \sum_{i=1}^{n} \{Y_i(1) - Y_i(0)\} \\
  = n^{-1} \sum_{i=1}^{n} Y_i(1) - n^{-1} \sum_{i=1}^{n} Y_i(0).
$$

In this study, the causal parameter of interest is the ATE between
always treated vs never treated \cite{liu2023section3}. After getting
the Average Treatment Effect (ATE) from Bayesian bootstrap, we will also
compare our results to the frequentist approach. The frequentist
Marginal Structural Models (MSMs) calculates visit specific propensity
scores, and fits the weighted linear regression \cite{liu2023section3}.

# Description of bayesmsm

The `bayesmsm` package is developed to implement Bayesian marginal
structural models (BMSMs) for longitudinal data analysis. It contains
three core functions: `bayesweight`, `bayesweight_cen`, and `bayesmsm`.
`bayesweight` estimates treatment weights using posterior samples of
$\alpha$ and $\beta$ via fitting a series of logistic regressions in a
Bayesian framework, whereas `bayesweight_cen` extends the function
`bayesweight` to handle right-censored data. `bayesmsm` then uses the
estimated treatment weights to perform Bayesian non-parametric bootstrap
so as to estimate causal effect. In this section, we describe these
functions and their usage in detail.

## Bayesian treatment effect weight estimation using `bayesweight`

-   The following code calls the function `bayesweight` to run JAGS and
    calculate the weights.
    -   Non-parallel computing requires that `n.chains = 1`. Parallel
        MCMC requires at least 2 chains because computing is running on
        1 core per chain, and we recommend using at most 2 chains less
        than the number of available cores on your computer.
    -   Running this function automatically saves a JAGS model file in
        the working directory, which the user can check to review the
        model specifications.
-   Parameters Description:
    -   `trtmodel.list`: A list of formulas corresponding to each time
        point with the time-specific treatment variable on the left hand
        side and pre-treatment covariates to be balanced on the right
        hand side. Interactions and functions of covariates are allowed.
    -   `data`: The dataset containing all the variables specified in
        trtmodel.list.
    -   `n.iter`: Total number of iterations for each chain (including
        burn-in).
    -   `n.burnin`: Number of iterations to discard at the beginning of
        the simulation (burn-in).
    -   `n.thin`: Thinning rate for the MCMC sampler.
    -   `n.chains`: Number of MCMC chains to run. For non-parallel
        execution, this should be set to 1. For parallel execution, it
        requires at least 2 chains.
    -   `seed`: Seed to ensure reproducibility.
    -   `parallel`: Logical flag indicating whether to run the MCMC
        chains in parallel. Default is TRUE.

`weights <- bayesweight(trtmodel.list = list(a_1 ~ w1 + w2 + L1_1 + L2_1,`

`a_2 ~ w1 + w2 + L1_1 + L2_1 + L1_2 + L2_2 + a_1),`

`data = testdata,`

`n.iter = 250,`

`n.burnin = 150,`

`n.thin = 5,`

`n.chains = 2,`

`seed = 890123,`

`parallel = TRUE)`

-   It returns a list containing:
    -   `weights`: The calculated weights for subject-specific treatment
        effects.

## Bayesian non-parametric bootstrap to maximize the utility function with respect to the causal effect using `bayesmsm`

The function `bayesmsm` estimates causal effect of time-varying
treatments. It uses subject-specific treatment assignmennt weights
*weights* calculated using `bayesweight` or `bayesweight_cen`, and
performs Bayesian non-parametric bootstrap to estimate the causal
parameters.

-   Parameters Description:
    -   `ymodel`: A formula representing the outcome model, which can
        include interactions and functions of covariates.
    -   `nvisit`: Specifies the number of visits or time points
        considered in the model.
    -   `reference`: The baseline or reference intervention across all
        visits, typically represented by a vector of zeros indicating no
        treatment (default is a vector of all zeros).
    -   `comparator`: The comparison intervention across all visits,
        typically represented by a vector of ones indicating full
        treatment (default is a vector of all ones).
    -   `family`: Specifies the outcome distribution family; use
        "gaussian" for continuous outcomes or "binomial" for binary
        outcomes (default is "gaussian").
    -   `data`: The dataset containing all variables required for the
        model.
    -   `wmean`: A vector of treatment assignment weights. Default is a
        vector of ones, implying equal weighting.
    -   `nboot`: The number of bootstrap iterations to perform for
        estimating the uncertainty around the causal estimates.
    -   `optim_method`: The optimization method used to find the best
        parameters in the model (default is 'BFGS').
    -   `seed`: A seed value to ensure reproducibility of results.
    -   `parallel`: A logical flag indicating whether to perform
        computations in parallel (default is TRUE).
    -   `ncore`: The number of cores to use for parallel computation
        (default is 4).

`model <- bayesmsm(ymodel = y ~ a_1+a_2,`
`nvisit = 2,`
`reference = c(rep(0,2)),`
`comparator = c(rep(1,2)),`
`family = "gaussian",`
`data = testdata,`
`wmean = weights,`
`nboot = 1000,`
`optim_method = "BFGS",`
`parallel = TRUE,`
`seed = 890123,`
`ncore = 2)`

-   It returns a model object which contains:
    -   `mean`, `sd`, `quantile`: the mean, standard deviation and 95%
        credible interval of the estimated causal effect (ATE). From the
        above results, the mean of ATE is approximately -3.161, which
        indicates that the expected outcome for always treated patients
        is, on average, 3.161 units less than that for never treated
        patients.
    -   `bootdata`: a data frame containing the bootstrap samples for
        the reference effect, comparator effect, and average treatment
        effect (ATE).
    -   `reference`, `comparator`: the reference level and comparator
        level the user chooses to compare. Here the reference level is
        never treated (0,0), and the comparator level is always treated
        (1,1).

# Numerical Examples and Implementation Using Simulated Dataset

In our simulation study, we will be using a longitudinal dataset
designed and simulated to mimic the complex real-world clinical data
\cite{liu2023section3}. In this dataset, there are 1,000 patients in
total with 3 visits, 2 of which patients were assigned a treatment. The
end-of-study outcome $Y$ is continuous and what we are interested in.
$w_1$ and $w_2$ are two baseline covariates mimicking sex and age, where
$w_1$ is a binary variable with values 0 (female) and 1 (male), and
$w_2$ is a continuous variable with mean 12.048. $L_1$ and $L_2$ emulate
time-dependent covariates, one binary and one continuous, reflecting
variables that might change with time during the study period. The
binary treatment variable, represented as $a_1$ and $a_2$ for visit 1
and 2 in the dataset, corresponds to the treatments $Z_1$ and $Z_2$ as
defined in our earlier discussion on Directed Acyclic Graphs (DAGs).
Finally, there is no missing data in the dataset. \cite{liu2023section3}
Table 1 shows an overview of this simulated dataset.

-   The simulated DAG

```{r}
library(DiagrammeR)
grViz("
    digraph causal {
    # Nodes
    node [shape=plaintext]
    W [label = 'w1, w2']
    L1 [label = 'L11, L21']
    Z1 [label = 'Z1']
    L2 [label = 'L12, L22']
    Z2 [label = 'Z2']
    Y [label = 'Y']
    
    # Edges
    edge [color=black, arrowhead=vee]
    rankdir = LR
    W->L1
    W->Z1
    W->L2
    W->Z2
    W->Y
    L1->Z1
    L1->L2
    L1->Z2
    L1->Y
    Z1->L2
    Z1->Z2
    Z1->Y
    L2->Z2
    L2->Y
    Z2->Y
    
    # Graph
    graph [overlap=true, fontsize=14]
    }")
```

```{r}
library(DT)
options(scipen = 999)

testdata <- read.csv("data/continuous_outcome_data.csv")

# look at the data;
datatable(testdata,
          rownames = FALSE,
          options = list(dom = 't')) %>%
  formatRound(columns=c('w2', 'L2_1', 'L2_2', 'y'), digits=2)
```

-   Frequency Counts by Treatment Combinations

```{r}
# frequency counts by treatment combinations;
table(testdata$a_1, testdata$a_2)
```

-   Suppose the causal parameter of interest is the average treatment
    effect between always treated and never treated,

$$
ATE = E(Y \mid Z_1 = 1, Z_2 = 1) - E(Y \mid Z_1 = 0, Z_2 = 0)
$$

-   Usage of functions on the simulated dataset:

```{r}
weights <- bayesweight(trtmodel.list = list(a_1 ~ w1 + w2 + L1_1 + L2_1,
                                             a_2 ~ w1 + w2 + L1_1 + L2_1 + L1_2 + L2_2 + a_1),
                        data = testdata,
                        n.iter = 250,
                        n.burnin = 150,
                        n.thin = 5,
                        n.chains = 2,
                        seed = 890123,
                        parallel = TRUE)
str(weights)
```

```{r}
model <- bayesmsm(ymodel = y ~ a_1+a_2,
                           nvisit = 2,
                           reference = c(rep(0,2)),
                           comparator = c(rep(1,2)),
                           family = "gaussian",
                           data = testdata,
                           wmean = weights,
                           nboot = 1000,
                           optim_method = "BFGS",
                           parallel = TRUE,
                           seed = 890123,
                           ncore = 2)
str(model)
```

# Discussion
